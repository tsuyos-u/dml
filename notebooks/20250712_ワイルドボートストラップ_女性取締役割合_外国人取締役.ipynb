{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "32f4d91e-a56a-47fe-8af5-07ae12b6b735",
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "from pathlib import Path\n",
    "\n",
    "from econml.dml import LinearDML, DML\n",
    "from econml.inference import BootstrapInference\n",
    "from lightgbm import LGBMRegressor, LGBMClassifier\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import tqdm\n",
    "\n",
    "from sklearn.linear_model import RidgeCV, LogisticRegression, LinearRegression\n",
    "from sklearn.model_selection import GroupKFold, StratifiedGroupKFold\n",
    "from sklearn.base import clone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "408d0ea7-672e-44de-91b4-e166073ff34e",
   "metadata": {},
   "outputs": [],
   "source": [
    "models = Path(\"models\") / \"wild_bootstrap\"\n",
    "models.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "data_path = Path(\"../data\")\n",
    "file_name = \"ToAnalysis_Winsorized_2015_2023_With_Profit_Asset.csv\"\n",
    "file_path = data_path / file_name\n",
    "\n",
    "df = pd.read_csv(file_path, parse_dates=['start date'])\n",
    "df.columns = [col.replace(\" \", \"_\").lower() for col in df.columns]\n",
    "df = df.sort_values(by=['ticker', 'start_date'])\n",
    "\n",
    "df[\"log_tobin_q_winsor\"] = np.log(df['tobin_q_winsor'])\n",
    "df[\"year\"] = df.start_date.dt.year\n",
    "df[\"roa\"] = df[\"net_income\"].div(df[\"total_assets\"])\n",
    "df[\"log_female_director_ratio\"] = np.log(df[\"female_director_ratio\"] + 1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "757effe8-8d64-497b-afdc-c7491da0c8fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "year = pd.get_dummies(df['year'], dtype='int', drop_first=True)\n",
    "industry = pd.get_dummies(df['industry_name'], dtype='int')\n",
    "industry = industry.drop(\"その他製品\", axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e3d40ef8-7e56-4ffc-bd89-65bc8c4ed915",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_cols = ['log_tobin_q_winsor']\n",
    "W_cols = [\n",
    "    'board_size', \n",
    "    'log_firm_age', \n",
    "    'log_sales',\n",
    "    'sales_growth', \n",
    "    'tangible_assets', \n",
    "    'leverage',\n",
    "#     'foreign_ownership',\n",
    "#     'managerial_ownership',\n",
    "]\n",
    "T_cols = ['female_director_ratio']\n",
    "G_cols = ['ticker']\n",
    "X_cols = ['foreign_ownership', 'managerial_ownership']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6b9418bf-1f94-450d-94b6-f81bd66da73a",
   "metadata": {},
   "outputs": [],
   "source": [
    "mundlak_W = df.groupby(by='ticker')[W_cols + X_cols].transform(\"mean\")\n",
    "mundlak_W.columns = [f\"{col}_mean\" for col in mundlak_W.columns]\n",
    "\n",
    "mundlak_T = df.groupby(by='ticker')[T_cols].transform(\"mean\")\n",
    "mundlak_T.columns = [f\"{col}_mean\" for col in mundlak_T.columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ee257181-39f0-43a9-ae2f-a73ea328a093",
   "metadata": {},
   "outputs": [],
   "source": [
    "# コントロール変数\n",
    "W = df[W_cols].join(mundlak_T).join(mundlak_W).join(year).join(industry)\n",
    "\n",
    "# 説明変数\n",
    "X = df[X_cols]# \n",
    "# .join(industry)\n",
    "\n",
    "# 出力\n",
    "Y = df[Y_cols]\n",
    "\n",
    "# 介入\n",
    "T = df[T_cols]\n",
    "\n",
    "# Groups\n",
    "G = df['ticker']\n",
    "\n",
    "tmp = pd.concat((W, X, Y, T, G), axis=1).dropna(how='any', axis=0)\n",
    "\n",
    "W = W.loc[tmp.index]\n",
    "X = X.loc[tmp.index]\n",
    "Y = Y.loc[tmp.index]\n",
    "T = T.loc[tmp.index]\n",
    "G = G.loc[tmp.index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "709f3d4b-ea09-492e-a23f-328f9308a68c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_y = LGBMRegressor(force_row_wise=True, verbose=-1) # \n",
    "model_t = LGBMRegressor(force_row_wise=True, verbose=-1) # LinearRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6f246563-6bf1-4679-b515-4fcbfd084e14",
   "metadata": {},
   "outputs": [],
   "source": [
    "dml0 = LinearDML(model_y=model_y, model_t=model_t,\n",
    "                 cv=GroupKFold(n_splits=3))\n",
    "dml0.fit(Y.values.ravel(),\n",
    "         T.values.ravel(),\n",
    "         X=X.values, \n",
    "         W=W.values, \n",
    "         groups=G.values, cache_values=True)\n",
    "\n",
    "y_res, t_res, _, _ = dml0.residuals_\n",
    "y_hat = Y.values.ravel() - y_res\n",
    "t_hat = T.values.ravel() - t_res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a36cc621-723b-4ded-934b-5e2c2c445d51",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                    | 0/100 [00:03<?, ?it/s]\n",
      "Exception ignored in: <bound method IPythonKernel._clean_thread_parent_frames of <ipykernel.ipkernel.IPythonKernel object at 0x120270c50>>\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/tsuyos-u/Library/Caches/pypoetry/virtualenvs/dml-r0_m-wiA-py3.11/lib/python3.11/site-packages/ipykernel/ipkernel.py\", line 775, in _clean_thread_parent_frames\n",
      "    def _clean_thread_parent_frames(\n",
      "\n",
      "KeyboardInterrupt: \n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[9]\u001b[39m\u001b[32m, line 15\u001b[39m\n\u001b[32m     10\u001b[39m t_star = t_hat + t_res * v  \u001b[38;5;66;03m# treatment も揺らすなら\u001b[39;00m\n\u001b[32m     12\u001b[39m dml_b = LinearDML(\n\u001b[32m     13\u001b[39m     model_y=model_y, model_t=model_t, cv=GroupKFold(n_splits=\u001b[32m3\u001b[39m)\n\u001b[32m     14\u001b[39m )\n\u001b[32m---> \u001b[39m\u001b[32m15\u001b[39m \u001b[43mdml_b\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     16\u001b[39m \u001b[43m    \u001b[49m\u001b[43my_star\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mt_star\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m=\u001b[49m\u001b[43mX\u001b[49m\u001b[43m.\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mW\u001b[49m\u001b[43m=\u001b[49m\u001b[43mW\u001b[49m\u001b[43m.\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgroups\u001b[49m\u001b[43m=\u001b[49m\u001b[43mG\u001b[49m\u001b[43m.\u001b[49m\u001b[43mvalues\u001b[49m\n\u001b[32m     17\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     19\u001b[39m ate.append(dml_b.ate(X=X.values))\n\u001b[32m     20\u001b[39m file_name = \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mb\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m02d\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m.joblib\u001b[39m\u001b[33m\"\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Library/Caches/pypoetry/virtualenvs/dml-r0_m-wiA-py3.11/lib/python3.11/site-packages/econml/dml/dml.py:821\u001b[39m, in \u001b[36mLinearDML.fit\u001b[39m\u001b[34m(self, Y, T, X, W, sample_weight, freq_weight, sample_var, groups, cache_values, inference)\u001b[39m\n\u001b[32m    782\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mfit\u001b[39m(\u001b[38;5;28mself\u001b[39m, Y, T, *, X=\u001b[38;5;28;01mNone\u001b[39;00m, W=\u001b[38;5;28;01mNone\u001b[39;00m, sample_weight=\u001b[38;5;28;01mNone\u001b[39;00m, freq_weight=\u001b[38;5;28;01mNone\u001b[39;00m, sample_var=\u001b[38;5;28;01mNone\u001b[39;00m, groups=\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m    783\u001b[39m         cache_values=\u001b[38;5;28;01mFalse\u001b[39;00m, inference=\u001b[33m'\u001b[39m\u001b[33mauto\u001b[39m\u001b[33m'\u001b[39m):\n\u001b[32m    784\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    785\u001b[39m \u001b[33;03m    Estimate the counterfactual model from data, i.e. estimates functions τ(·,·,·), ∂τ(·,·).\u001b[39;00m\n\u001b[32m    786\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m    819\u001b[39m \u001b[33;03m    self\u001b[39;00m\n\u001b[32m    820\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m821\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mY\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mT\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m=\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mW\u001b[49m\u001b[43m=\u001b[49m\u001b[43mW\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    822\u001b[39m \u001b[43m                       \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m=\u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfreq_weight\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfreq_weight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample_var\u001b[49m\u001b[43m=\u001b[49m\u001b[43msample_var\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgroups\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgroups\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    823\u001b[39m \u001b[43m                       \u001b[49m\u001b[43mcache_values\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcache_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    824\u001b[39m \u001b[43m                       \u001b[49m\u001b[43minference\u001b[49m\u001b[43m=\u001b[49m\u001b[43minference\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Library/Caches/pypoetry/virtualenvs/dml-r0_m-wiA-py3.11/lib/python3.11/site-packages/econml/dml/dml.py:589\u001b[39m, in \u001b[36mDML.fit\u001b[39m\u001b[34m(self, Y, T, X, W, sample_weight, freq_weight, sample_var, groups, cache_values, inference)\u001b[39m\n\u001b[32m    550\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mfit\u001b[39m(\u001b[38;5;28mself\u001b[39m, Y, T, *, X=\u001b[38;5;28;01mNone\u001b[39;00m, W=\u001b[38;5;28;01mNone\u001b[39;00m, sample_weight=\u001b[38;5;28;01mNone\u001b[39;00m, freq_weight=\u001b[38;5;28;01mNone\u001b[39;00m, sample_var=\u001b[38;5;28;01mNone\u001b[39;00m, groups=\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m    551\u001b[39m         cache_values=\u001b[38;5;28;01mFalse\u001b[39;00m, inference=\u001b[33m'\u001b[39m\u001b[33mauto\u001b[39m\u001b[33m'\u001b[39m):\n\u001b[32m    552\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    553\u001b[39m \u001b[33;03m    Estimate the counterfactual model from data, i.e. estimates functions τ(·,·,·), ∂τ(·,·).\u001b[39;00m\n\u001b[32m    554\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m    587\u001b[39m \u001b[33;03m    self\u001b[39;00m\n\u001b[32m    588\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m589\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mY\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mT\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m=\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mW\u001b[49m\u001b[43m=\u001b[49m\u001b[43mW\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m=\u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfreq_weight\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfreq_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    590\u001b[39m \u001b[43m                       \u001b[49m\u001b[43msample_var\u001b[49m\u001b[43m=\u001b[49m\u001b[43msample_var\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgroups\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgroups\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    591\u001b[39m \u001b[43m                       \u001b[49m\u001b[43mcache_values\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcache_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    592\u001b[39m \u001b[43m                       \u001b[49m\u001b[43minference\u001b[49m\u001b[43m=\u001b[49m\u001b[43minference\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Library/Caches/pypoetry/virtualenvs/dml-r0_m-wiA-py3.11/lib/python3.11/site-packages/econml/dml/_rlearner.py:415\u001b[39m, in \u001b[36m_RLearner.fit\u001b[39m\u001b[34m(self, Y, T, X, W, sample_weight, freq_weight, sample_var, groups, cache_values, inference)\u001b[39m\n\u001b[32m    378\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    379\u001b[39m \u001b[33;03mEstimate the counterfactual model from data, i.e. estimates function :math:`\\\\theta(\\\\cdot)`.\u001b[39;00m\n\u001b[32m    380\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m    412\u001b[39m \u001b[33;03mself: _RLearner instance\u001b[39;00m\n\u001b[32m    413\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    414\u001b[39m \u001b[38;5;66;03m# Replacing fit from _OrthoLearner, to enforce Z=None and improve the docstring\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m415\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mY\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mT\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m=\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mW\u001b[49m\u001b[43m=\u001b[49m\u001b[43mW\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    416\u001b[39m \u001b[43m                   \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m=\u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfreq_weight\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfreq_weight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample_var\u001b[49m\u001b[43m=\u001b[49m\u001b[43msample_var\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgroups\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgroups\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    417\u001b[39m \u001b[43m                   \u001b[49m\u001b[43mcache_values\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcache_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    418\u001b[39m \u001b[43m                   \u001b[49m\u001b[43minference\u001b[49m\u001b[43m=\u001b[49m\u001b[43minference\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Library/Caches/pypoetry/virtualenvs/dml-r0_m-wiA-py3.11/lib/python3.11/site-packages/econml/_cate_estimator.py:131\u001b[39m, in \u001b[36mBaseCateEstimator._wrap_fit.<locals>.call\u001b[39m\u001b[34m(self, Y, T, inference, *args, **kwargs)\u001b[39m\n\u001b[32m    129\u001b[39m     inference.prefit(\u001b[38;5;28mself\u001b[39m, Y, T, *args, **kwargs)\n\u001b[32m    130\u001b[39m \u001b[38;5;66;03m# call the wrapped fit method\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m131\u001b[39m \u001b[43mm\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mY\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mT\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    132\u001b[39m \u001b[38;5;28mself\u001b[39m._postfit(Y, T, *args, **kwargs)\n\u001b[32m    133\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m inference \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    134\u001b[39m     \u001b[38;5;66;03m# NOTE: we call inference fit *after* calling the main fit method\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Library/Caches/pypoetry/virtualenvs/dml-r0_m-wiA-py3.11/lib/python3.11/site-packages/econml/_ortho_learner.py:822\u001b[39m, in \u001b[36m_OrthoLearner.fit\u001b[39m\u001b[34m(self, Y, T, X, W, Z, sample_weight, freq_weight, sample_var, groups, cache_values, inference, only_final, check_input)\u001b[39m\n\u001b[32m    820\u001b[39m     nuisances, fitted_models, new_inds, scores = ray.get(\u001b[38;5;28mself\u001b[39m.nuisances_ref[idx])\n\u001b[32m    821\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m822\u001b[39m     nuisances, fitted_models, new_inds, scores = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_fit_nuisances\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    823\u001b[39m \u001b[43m        \u001b[49m\u001b[43mY\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mT\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mW\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mZ\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m=\u001b[49m\u001b[43msample_weight_nuisances\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgroups\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgroups\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    824\u001b[39m all_nuisances.append(nuisances)\n\u001b[32m    825\u001b[39m \u001b[38;5;28mself\u001b[39m._models_nuisance.append(fitted_models)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Library/Caches/pypoetry/virtualenvs/dml-r0_m-wiA-py3.11/lib/python3.11/site-packages/econml/_ortho_learner.py:972\u001b[39m, in \u001b[36m_OrthoLearner._fit_nuisances\u001b[39m\u001b[34m(self, Y, T, X, W, Z, sample_weight, groups)\u001b[39m\n\u001b[32m    969\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    970\u001b[39m         folds = splitter.split(to_split, strata)\n\u001b[32m--> \u001b[39m\u001b[32m972\u001b[39m nuisances, fitted_models, fitted_inds, scores = \u001b[43m_crossfit\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_ortho_learner_model_nuisance\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfolds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    973\u001b[39m \u001b[43m                                                          \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43muse_ray\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mray_remote_func_options\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mY\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mT\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    974\u001b[39m \u001b[43m                                                          \u001b[49m\u001b[43mX\u001b[49m\u001b[43m=\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mW\u001b[49m\u001b[43m=\u001b[49m\u001b[43mW\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mZ\u001b[49m\u001b[43m=\u001b[49m\u001b[43mZ\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m=\u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    975\u001b[39m \u001b[43m                                                          \u001b[49m\u001b[43mgroups\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgroups\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    976\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m nuisances, fitted_models, fitted_inds, scores\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Library/Caches/pypoetry/virtualenvs/dml-r0_m-wiA-py3.11/lib/python3.11/site-packages/econml/_ortho_learner.py:280\u001b[39m, in \u001b[36m_crossfit\u001b[39m\u001b[34m(models, folds, use_ray, ray_remote_fun_option, *args, **kwargs)\u001b[39m\n\u001b[32m    278\u001b[39m     nuisance_temp, model_out, score_temp = ray.get(fold_refs[idx])\n\u001b[32m    279\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m280\u001b[39m     nuisance_temp, model_out, score_temp = \u001b[43m_fit_fold\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_idxs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_idxs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    281\u001b[39m \u001b[43m                                                     \u001b[49m\u001b[43mcalculate_scores\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maccumulated_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    283\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m idx == \u001b[32m0\u001b[39m:\n\u001b[32m    284\u001b[39m     nuisances = \u001b[38;5;28mtuple\u001b[39m([np.full((n,) + nuis.shape[\u001b[32m1\u001b[39m:], np.nan)\n\u001b[32m    285\u001b[39m                       \u001b[38;5;28;01mfor\u001b[39;00m nuis \u001b[38;5;129;01min\u001b[39;00m nuisance_temp])\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Library/Caches/pypoetry/virtualenvs/dml-r0_m-wiA-py3.11/lib/python3.11/site-packages/econml/_ortho_learner.py:99\u001b[39m, in \u001b[36m_fit_fold\u001b[39m\u001b[34m(model, train_idxs, test_idxs, calculate_scores, args, kwargs)\u001b[39m\n\u001b[32m     96\u001b[39m kwargs_train = {key: var[train_idxs] \u001b[38;5;28;01mfor\u001b[39;00m key, var \u001b[38;5;129;01min\u001b[39;00m kwargs.items()}\n\u001b[32m     97\u001b[39m kwargs_test = {key: var[test_idxs] \u001b[38;5;28;01mfor\u001b[39;00m key, var \u001b[38;5;129;01min\u001b[39;00m kwargs.items()}\n\u001b[32m---> \u001b[39m\u001b[32m99\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    100\u001b[39m nuisance_temp = model.predict(*args_test, **kwargs_test)\n\u001b[32m    102\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(nuisance_temp, \u001b[38;5;28mtuple\u001b[39m):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Library/Caches/pypoetry/virtualenvs/dml-r0_m-wiA-py3.11/lib/python3.11/site-packages/econml/dml/_rlearner.py:55\u001b[39m, in \u001b[36m_ModelNuisance.train\u001b[39m\u001b[34m(self, is_selecting, folds, Y, T, X, W, Z, sample_weight, groups)\u001b[39m\n\u001b[32m     52\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m Z \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[33m\"\u001b[39m\u001b[33mCannot accept instrument!\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m     53\u001b[39m \u001b[38;5;28mself\u001b[39m._model_t.train(is_selecting, folds, X, W, T, **\n\u001b[32m     54\u001b[39m                     filter_none_kwargs(sample_weight=sample_weight, groups=groups))\n\u001b[32m---> \u001b[39m\u001b[32m55\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_model_y\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mis_selecting\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfolds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mW\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mY\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\n\u001b[32m     56\u001b[39m \u001b[43m                    \u001b[49m\u001b[43mfilter_none_kwargs\u001b[49m\u001b[43m(\u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m=\u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgroups\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgroups\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     57\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Library/Caches/pypoetry/virtualenvs/dml-r0_m-wiA-py3.11/lib/python3.11/site-packages/econml/dml/dml.py:95\u001b[39m, in \u001b[36m_FirstStageSelector.train\u001b[39m\u001b[34m(self, is_selecting, folds, X, W, Target, sample_weight, groups)\u001b[39m\n\u001b[32m     91\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33mProvided crossfit folds contain training splits that \u001b[39m\u001b[33m\"\u001b[39m +\n\u001b[32m     92\u001b[39m                              \u001b[33m\"\u001b[39m\u001b[33mdon\u001b[39m\u001b[33m'\u001b[39m\u001b[33mt contain all treatments\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     93\u001b[39m     Target = inverse_onehot(Target)\n\u001b[32m---> \u001b[39m\u001b[32m95\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_model\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mis_selecting\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfolds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_combine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mW\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mTarget\u001b[49m\u001b[43m.\u001b[49m\u001b[43mshape\u001b[49m\u001b[43m[\u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mTarget\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     96\u001b[39m \u001b[43m                  \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mfilter_none_kwargs\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgroups\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgroups\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m=\u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     97\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Library/Caches/pypoetry/virtualenvs/dml-r0_m-wiA-py3.11/lib/python3.11/site-packages/econml/sklearn_extensions/model_selection.py:407\u001b[39m, in \u001b[36mFixedModelSelector.train\u001b[39m\u001b[34m(self, is_selecting, folds, X, y, groups, **kwargs)\u001b[39m\n\u001b[32m    404\u001b[39m         \u001b[38;5;28mself\u001b[39m._score = np.mean(scores)\n\u001b[32m    405\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    406\u001b[39m     \u001b[38;5;66;03m# we need to train the model on the data\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m407\u001b[39m     \u001b[43m_fit_with_groups\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgroups\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgroups\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    409\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Library/Caches/pypoetry/virtualenvs/dml-r0_m-wiA-py3.11/lib/python3.11/site-packages/econml/sklearn_extensions/model_selection.py:378\u001b[39m, in \u001b[36m_fit_with_groups\u001b[39m\u001b[34m(model, X, y, sub_model, groups, **kwargs)\u001b[39m\n\u001b[32m    375\u001b[39m             sub_model.cv = old_cv\n\u001b[32m    377\u001b[39m \u001b[38;5;66;03m# drop groups from arg list, which were already used at the outer level and may not be supported by the model\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m378\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmodel\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Library/Caches/pypoetry/virtualenvs/dml-r0_m-wiA-py3.11/lib/python3.11/site-packages/lightgbm/sklearn.py:1398\u001b[39m, in \u001b[36mLGBMRegressor.fit\u001b[39m\u001b[34m(self, X, y, sample_weight, init_score, eval_set, eval_names, eval_sample_weight, eval_init_score, eval_metric, feature_name, categorical_feature, callbacks, init_model)\u001b[39m\n\u001b[32m   1381\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mfit\u001b[39m(  \u001b[38;5;66;03m# type: ignore[override]\u001b[39;00m\n\u001b[32m   1382\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   1383\u001b[39m     X: _LGBM_ScikitMatrixLike,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1395\u001b[39m     init_model: Optional[Union[\u001b[38;5;28mstr\u001b[39m, Path, Booster, LGBMModel]] = \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m   1396\u001b[39m ) -> \u001b[33m\"\u001b[39m\u001b[33mLGBMRegressor\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m   1397\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Docstring is inherited from the LGBMModel.\"\"\"\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1398\u001b[39m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1399\u001b[39m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1400\u001b[39m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1401\u001b[39m \u001b[43m        \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m=\u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1402\u001b[39m \u001b[43m        \u001b[49m\u001b[43minit_score\u001b[49m\u001b[43m=\u001b[49m\u001b[43minit_score\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1403\u001b[39m \u001b[43m        \u001b[49m\u001b[43meval_set\u001b[49m\u001b[43m=\u001b[49m\u001b[43meval_set\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1404\u001b[39m \u001b[43m        \u001b[49m\u001b[43meval_names\u001b[49m\u001b[43m=\u001b[49m\u001b[43meval_names\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1405\u001b[39m \u001b[43m        \u001b[49m\u001b[43meval_sample_weight\u001b[49m\u001b[43m=\u001b[49m\u001b[43meval_sample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1406\u001b[39m \u001b[43m        \u001b[49m\u001b[43meval_init_score\u001b[49m\u001b[43m=\u001b[49m\u001b[43meval_init_score\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1407\u001b[39m \u001b[43m        \u001b[49m\u001b[43meval_metric\u001b[49m\u001b[43m=\u001b[49m\u001b[43meval_metric\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1408\u001b[39m \u001b[43m        \u001b[49m\u001b[43mfeature_name\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfeature_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1409\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcategorical_feature\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcategorical_feature\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1410\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1411\u001b[39m \u001b[43m        \u001b[49m\u001b[43minit_model\u001b[49m\u001b[43m=\u001b[49m\u001b[43minit_model\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1412\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1413\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Library/Caches/pypoetry/virtualenvs/dml-r0_m-wiA-py3.11/lib/python3.11/site-packages/lightgbm/sklearn.py:1049\u001b[39m, in \u001b[36mLGBMModel.fit\u001b[39m\u001b[34m(self, X, y, sample_weight, init_score, group, eval_set, eval_names, eval_sample_weight, eval_class_weight, eval_init_score, eval_group, eval_metric, feature_name, categorical_feature, callbacks, init_model)\u001b[39m\n\u001b[32m   1046\u001b[39m evals_result: _EvalResultDict = {}\n\u001b[32m   1047\u001b[39m callbacks.append(record_evaluation(evals_result))\n\u001b[32m-> \u001b[39m\u001b[32m1049\u001b[39m \u001b[38;5;28mself\u001b[39m._Booster = \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1050\u001b[39m \u001b[43m    \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m=\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1051\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtrain_set\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtrain_set\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1052\u001b[39m \u001b[43m    \u001b[49m\u001b[43mnum_boost_round\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mn_estimators\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1053\u001b[39m \u001b[43m    \u001b[49m\u001b[43mvalid_sets\u001b[49m\u001b[43m=\u001b[49m\u001b[43mvalid_sets\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1054\u001b[39m \u001b[43m    \u001b[49m\u001b[43mvalid_names\u001b[49m\u001b[43m=\u001b[49m\u001b[43meval_names\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1055\u001b[39m \u001b[43m    \u001b[49m\u001b[43mfeval\u001b[49m\u001b[43m=\u001b[49m\u001b[43meval_metrics_callable\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore[arg-type]\u001b[39;49;00m\n\u001b[32m   1056\u001b[39m \u001b[43m    \u001b[49m\u001b[43minit_model\u001b[49m\u001b[43m=\u001b[49m\u001b[43minit_model\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1057\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1058\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1060\u001b[39m \u001b[38;5;66;03m# This populates the property self.n_features_, the number of features in the fitted model,\u001b[39;00m\n\u001b[32m   1061\u001b[39m \u001b[38;5;66;03m# and so should only be set after fitting.\u001b[39;00m\n\u001b[32m   1062\u001b[39m \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[32m   1063\u001b[39m \u001b[38;5;66;03m# The related property self._n_features_in, which populates self.n_features_in_,\u001b[39;00m\n\u001b[32m   1064\u001b[39m \u001b[38;5;66;03m# is set BEFORE fitting.\u001b[39;00m\n\u001b[32m   1065\u001b[39m \u001b[38;5;28mself\u001b[39m._n_features = \u001b[38;5;28mself\u001b[39m._Booster.num_feature()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Library/Caches/pypoetry/virtualenvs/dml-r0_m-wiA-py3.11/lib/python3.11/site-packages/lightgbm/engine.py:322\u001b[39m, in \u001b[36mtrain\u001b[39m\u001b[34m(params, train_set, num_boost_round, valid_sets, valid_names, feval, init_model, keep_training_booster, callbacks)\u001b[39m\n\u001b[32m    310\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m cb \u001b[38;5;129;01min\u001b[39;00m callbacks_before_iter:\n\u001b[32m    311\u001b[39m     cb(\n\u001b[32m    312\u001b[39m         callback.CallbackEnv(\n\u001b[32m    313\u001b[39m             model=booster,\n\u001b[32m   (...)\u001b[39m\u001b[32m    319\u001b[39m         )\n\u001b[32m    320\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m322\u001b[39m \u001b[43mbooster\u001b[49m\u001b[43m.\u001b[49m\u001b[43mupdate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfobj\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfobj\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    324\u001b[39m evaluation_result_list: List[_LGBM_BoosterEvalMethodResultType] = []\n\u001b[32m    325\u001b[39m \u001b[38;5;66;03m# check evaluation result.\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Library/Caches/pypoetry/virtualenvs/dml-r0_m-wiA-py3.11/lib/python3.11/site-packages/lightgbm/basic.py:4155\u001b[39m, in \u001b[36mBooster.update\u001b[39m\u001b[34m(self, train_set, fobj)\u001b[39m\n\u001b[32m   4152\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.__set_objective_to_none:\n\u001b[32m   4153\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m LightGBMError(\u001b[33m\"\u001b[39m\u001b[33mCannot update due to null objective function.\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m   4154\u001b[39m _safe_call(\n\u001b[32m-> \u001b[39m\u001b[32m4155\u001b[39m     \u001b[43m_LIB\u001b[49m\u001b[43m.\u001b[49m\u001b[43mLGBM_BoosterUpdateOneIter\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   4156\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   4157\u001b[39m \u001b[43m        \u001b[49m\u001b[43mctypes\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbyref\u001b[49m\u001b[43m(\u001b[49m\u001b[43mis_finished\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   4158\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   4159\u001b[39m )\n\u001b[32m   4160\u001b[39m \u001b[38;5;28mself\u001b[39m.__is_predicted_cur_iter = [\u001b[38;5;28;01mFalse\u001b[39;00m \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mself\u001b[39m.__num_dataset)]\n\u001b[32m   4161\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m is_finished.value == \u001b[32m1\u001b[39m\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "groups_unique = G.unique()\n",
    "rng   = np.random.RandomState(42)\n",
    "\n",
    "n_boot = 100\n",
    "ate = []\n",
    "for b in tqdm.tqdm(range(n_boot)):\n",
    "    v_g = rng.choice([-1, 1], size=len(groups_unique))\n",
    "    v = v_g[np.searchsorted(groups_unique, G)]\n",
    "    y_star = y_hat + y_res * v\n",
    "    t_star = t_hat + t_res * v  # treatment も揺らすなら\n",
    "\n",
    "    dml_b = LinearDML(\n",
    "        model_y=model_y, model_t=model_t, cv=GroupKFold(n_splits=3)\n",
    "    )\n",
    "    dml_b.fit(\n",
    "        y_star, t_star, X=X.values, W=W.values, groups=G.values\n",
    "    )\n",
    "    \n",
    "    ate.append(dml_b.ate(X=X.values))\n",
    "    file_name = f\"{b:02d}.joblib\"\n",
    "    file_path = models / file_name\n",
    "    joblib.dump(dml_b, file_path, compress=3)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5c2cbdfa-93d6-4850-aec4-c20dfd822b86",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.23759334319869158"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# within 変換と\n",
    "# between 変換\n",
    "dml0.ate(X=X)\n",
    "# 0.0025"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd9cf425-d8de-44fa-ba7e-f8df2e320fdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pd.Series(data=dml0.coef_, index=W.columns)\n",
    "# pd.Series(ate).median()\n",
    "# (pd.Series(ate).value_counts().sort_index().cumsum() / 100).plot()\n",
    "# sns.scatterplot(x=t_hat, y=np.sqrt(t_res / t_res.std()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6667e052-1817-43c9-a333-c04d9d458d34",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dml0.intercept_\n",
    "# dml0.ate(X=X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cef6816-82eb-4ccd-8dfe-1372f6aaac31",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pd.Series(data=dml0.coef_, index=X.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c981d2dd-87c0-4610-adfc-4b8e82521b38",
   "metadata": {},
   "outputs": [],
   "source": [
    "# managerial ownershipが高い"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f85df66-c92e-4146-9d0a-4a9930504229",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pd.Series(ate).median() * 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07ba4b7d-5b5b-4466-b83e-86a0e6a6cfc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dml_b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b74ee8d-d0d8-4ba9-8077-f30ee5492f1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# nuisance "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea608de6-8a1c-4fd3-8e89-b8e711fb163f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pd.Series(ate).quantile(0.025)\n",
    "# pd.Series(ate).quantile(0.975)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7222e7a6-3009-4c55-917d-25cfde6b1ec4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.exp(pd.Series(ate).median() * 0.1) - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "100c7131-d3ab-4f9c-bf1a-e404a090add0",
   "metadata": {},
   "outputs": [],
   "source": [
    "fe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69cbccb3-2433-4865-ac0f-e4cc40f792de",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
