{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d93c26ce-4034-4421-b568-21f217cb5c52",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import joblib\n",
    "from pathlib import Path\n",
    "\n",
    "from econml.dml import LinearDML, DML\n",
    "from catboost import CatBoostClassifier, CatBoostRegressor\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import tqdm\n",
    "\n",
    "from sklearn.model_selection import GroupKFold, StratifiedGroupKFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f01d9eab-71ab-4414-8319-90cf47562a4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GroupStratifiedKFold:\n",
    "    def __init__(self, n_splits: int = 3, random_state: int = None):\n",
    "        self.sgk = StratifiedGroupKFold(\n",
    "            n_splits=n_splits,\n",
    "            shuffle=True,\n",
    "            random_state=random_state\n",
    "        )\n",
    "\n",
    "    def split(self, X, y, groups):\n",
    "        return self.sgk.split(X, y, groups)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e4b462d5-619d-4af4-b3ab-64ab5f867d0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "models = Path(\"models\") / \"simple\" / \"threshold_effect\"\n",
    "models.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "data_path = Path(\"../data\")\n",
    "file_name = \"ToAnalysis_Winsorized_2015_2023_With_Profit_Asset.csv\"\n",
    "file_path = data_path / file_name\n",
    "\n",
    "df = pd.read_csv(file_path, parse_dates=['start date'])\n",
    "df.columns = [col.replace(\" \", \"_\").lower() for col in df.columns]\n",
    "df = df.sort_values(by=['ticker', 'start_date'])\n",
    "\n",
    "df[\"log_tobin_q_winsor\"] = np.log(df['tobin_q_winsor'])\n",
    "df[\"year\"] = df.start_date.dt.year\n",
    "df[\"roa\"] = df[\"net_income\"].div(df[\"total_assets\"])\n",
    "df[\"log_total_assets\"] = np.log(df['total_assets'])\n",
    "df[\"log_leverage\"] = np.log(df['leverage'])\n",
    "df[\"log_tangible_assets\"] = np.log(df['tangible_assets'])\n",
    "\n",
    "df = df.assign(lag_log_tobin_q_winsor=df.groupby(by=['ticker']).log_tobin_q_winsor.shift(-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b3ec3e1f-9357-442f-b611-d88567809ce8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['female_threshold'] = df['female_director_ratio'].mask((df['female_director_ratio']<= 0.1) & (df['female_director_ratio']>= 0), 0)\n",
    "df['female_threshold'] = df['female_threshold'].mask((df['female_director_ratio']<= 0.2) & (df['female_director_ratio']> 0.1), 1)\n",
    "df['female_threshold'] = df['female_threshold'].mask((df['female_director_ratio']<= 0.3) & (df['female_director_ratio']> 0.2), 2)\n",
    "df['female_threshold'] = df['female_threshold'].mask((df['female_director_ratio']> 0.3), 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fe64f85e-2101-4db7-8988-82e224917613",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 年の固定効果\n",
    "year = pd.get_dummies(df['year'], dtype='int')\n",
    "year = year.drop(2015, axis=1)\n",
    "\n",
    "# 業種の固定効果\n",
    "industry = pd.get_dummies(df['industry_name'], dtype='int')\n",
    "industry = industry.drop(\"その他製品\", axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3aae164b-e480-4044-817b-1aa8ac9d41a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_cols = ['log_tobin_q_winsor']\n",
    "\n",
    "# Lag Version\n",
    "Y_cols = ['log_tobin_q_winsor']\n",
    "\n",
    "# Control 変数 (ROAは入れた方が予測性能がよくなる)\n",
    "W_cols = [\n",
    "    'board_size', \n",
    "    'log_firm_age', \n",
    "    'log_sales',\n",
    "    'sales_growth', \n",
    "    'foreign_ownership', \n",
    "    'managerial_ownership',\n",
    "    'log_tangible_assets', \n",
    "    'log_leverage',\n",
    "    'roa',\n",
    "    'net_income'\n",
    "]\n",
    "\n",
    "X_cols = []\n",
    "T_cols = ['female_threshold']\n",
    "G_cols = ['ticker']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f021bc59-8660-40ed-830d-51f50ed0959e",
   "metadata": {},
   "outputs": [],
   "source": [
    "mundlak_W = df.groupby(by='ticker')[W_cols + X_cols].transform(\"mean\")\n",
    "mundlak_W.columns = [f\"{col}_mean\" for col in mundlak_W.columns]\n",
    "\n",
    "mundlak_T = df.groupby(by='ticker')[T_cols].transform(\"mean\")\n",
    "mundlak_T.columns = [f\"{col}_mean\" for col in mundlak_T.columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cddebf08-9d16-4bc8-b29a-80bc665e1c28",
   "metadata": {},
   "outputs": [],
   "source": [
    "# コントロール変数\n",
    "W = df[W_cols]\n",
    "W = W.join(mundlak_T).join(mundlak_W)\n",
    "W = W.join(year).join(industry)\n",
    "\n",
    "# 説明変数\n",
    "X = df[X_cols]\n",
    "\n",
    "# 出力\n",
    "Y = df[Y_cols]\n",
    "\n",
    "# 介入\n",
    "T = df[T_cols]\n",
    "\n",
    "# Groups\n",
    "G = df['ticker']\n",
    "\n",
    "tmp = pd.concat((W, X, Y, T, G), axis=1).dropna(how='any', axis=0)\n",
    "\n",
    "W = W.loc[tmp.index]\n",
    "X = X.loc[tmp.index]\n",
    "Y = Y.loc[tmp.index]\n",
    "T = T.loc[tmp.index]\n",
    "G = G.loc[tmp.index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "24c63308-d682-42a0-b444-d74c6dabd0a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Catboost を使用\n",
    "model_y = CatBoostRegressor(loss_function=\"RMSE\", verbose=0)\n",
    "model_t = CatBoostClassifier(\n",
    "    loss_function=\"MultiClass\",\n",
    "    eval_metric=\"MultiClass\",  # 学習時の指標は log-loss\n",
    "    verbose=0\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "43177ad1-5658-4b9b-8d5c-95791e9a5fa2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|▋                                                                                                                                                                             | 2/500 [00:27<1:55:57, 13.97s/it]\n",
      "Exception ignored in: <bound method IPythonKernel._clean_thread_parent_frames of <ipykernel.ipkernel.IPythonKernel object at 0x111c7d590>>\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/tsuyos-u/Library/Caches/pypoetry/virtualenvs/dml-r0_m-wiA-py3.11/lib/python3.11/site-packages/ipykernel/ipkernel.py\", line 775, in _clean_thread_parent_frames\n",
      "    def _clean_thread_parent_frames(\n",
      "\n",
      "KeyboardInterrupt: \n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[10]\u001b[39m\u001b[32m, line 18\u001b[39m\n\u001b[32m     10\u001b[39m idx = np.concatenate([np.where(G == g)[\u001b[32m0\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m g \u001b[38;5;129;01min\u001b[39;00m sampled_groups])\n\u001b[32m     12\u001b[39m dml_b = LinearDML(\n\u001b[32m     13\u001b[39m     model_y = model_y,\n\u001b[32m     14\u001b[39m     model_t = model_t, \n\u001b[32m     15\u001b[39m     discrete_treatment=\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[32m     16\u001b[39m     cv = GroupStratifiedKFold(n_splits=\u001b[32m3\u001b[39m)\n\u001b[32m     17\u001b[39m )\n\u001b[32m---> \u001b[39m\u001b[32m18\u001b[39m \u001b[43mdml_b\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mY\u001b[49m\u001b[43m.\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m.\u001b[49m\u001b[43mravel\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     19\u001b[39m \u001b[43m          \u001b[49m\u001b[43mT\u001b[49m\u001b[43m.\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m.\u001b[49m\u001b[43mravel\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     20\u001b[39m \u001b[43m          \u001b[49m\u001b[43mW\u001b[49m\u001b[43m=\u001b[49m\u001b[43mW\u001b[49m\u001b[43m.\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     21\u001b[39m \u001b[43m          \u001b[49m\u001b[43mgroups\u001b[49m\u001b[43m=\u001b[49m\u001b[43mG\u001b[49m\u001b[43m.\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     23\u001b[39m ate.append(dml_b.ate())\n\u001b[32m     24\u001b[39m file_name = \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mb\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m02d\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m.joblib\u001b[39m\u001b[33m\"\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Library/Caches/pypoetry/virtualenvs/dml-r0_m-wiA-py3.11/lib/python3.11/site-packages/econml/dml/dml.py:821\u001b[39m, in \u001b[36mLinearDML.fit\u001b[39m\u001b[34m(self, Y, T, X, W, sample_weight, freq_weight, sample_var, groups, cache_values, inference)\u001b[39m\n\u001b[32m    782\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mfit\u001b[39m(\u001b[38;5;28mself\u001b[39m, Y, T, *, X=\u001b[38;5;28;01mNone\u001b[39;00m, W=\u001b[38;5;28;01mNone\u001b[39;00m, sample_weight=\u001b[38;5;28;01mNone\u001b[39;00m, freq_weight=\u001b[38;5;28;01mNone\u001b[39;00m, sample_var=\u001b[38;5;28;01mNone\u001b[39;00m, groups=\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m    783\u001b[39m         cache_values=\u001b[38;5;28;01mFalse\u001b[39;00m, inference=\u001b[33m'\u001b[39m\u001b[33mauto\u001b[39m\u001b[33m'\u001b[39m):\n\u001b[32m    784\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    785\u001b[39m \u001b[33;03m    Estimate the counterfactual model from data, i.e. estimates functions τ(·,·,·), ∂τ(·,·).\u001b[39;00m\n\u001b[32m    786\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m    819\u001b[39m \u001b[33;03m    self\u001b[39;00m\n\u001b[32m    820\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m821\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mY\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mT\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m=\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mW\u001b[49m\u001b[43m=\u001b[49m\u001b[43mW\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    822\u001b[39m \u001b[43m                       \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m=\u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfreq_weight\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfreq_weight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample_var\u001b[49m\u001b[43m=\u001b[49m\u001b[43msample_var\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgroups\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgroups\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    823\u001b[39m \u001b[43m                       \u001b[49m\u001b[43mcache_values\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcache_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    824\u001b[39m \u001b[43m                       \u001b[49m\u001b[43minference\u001b[49m\u001b[43m=\u001b[49m\u001b[43minference\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Library/Caches/pypoetry/virtualenvs/dml-r0_m-wiA-py3.11/lib/python3.11/site-packages/econml/dml/dml.py:589\u001b[39m, in \u001b[36mDML.fit\u001b[39m\u001b[34m(self, Y, T, X, W, sample_weight, freq_weight, sample_var, groups, cache_values, inference)\u001b[39m\n\u001b[32m    550\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mfit\u001b[39m(\u001b[38;5;28mself\u001b[39m, Y, T, *, X=\u001b[38;5;28;01mNone\u001b[39;00m, W=\u001b[38;5;28;01mNone\u001b[39;00m, sample_weight=\u001b[38;5;28;01mNone\u001b[39;00m, freq_weight=\u001b[38;5;28;01mNone\u001b[39;00m, sample_var=\u001b[38;5;28;01mNone\u001b[39;00m, groups=\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m    551\u001b[39m         cache_values=\u001b[38;5;28;01mFalse\u001b[39;00m, inference=\u001b[33m'\u001b[39m\u001b[33mauto\u001b[39m\u001b[33m'\u001b[39m):\n\u001b[32m    552\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    553\u001b[39m \u001b[33;03m    Estimate the counterfactual model from data, i.e. estimates functions τ(·,·,·), ∂τ(·,·).\u001b[39;00m\n\u001b[32m    554\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m    587\u001b[39m \u001b[33;03m    self\u001b[39;00m\n\u001b[32m    588\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m589\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mY\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mT\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m=\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mW\u001b[49m\u001b[43m=\u001b[49m\u001b[43mW\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m=\u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfreq_weight\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfreq_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    590\u001b[39m \u001b[43m                       \u001b[49m\u001b[43msample_var\u001b[49m\u001b[43m=\u001b[49m\u001b[43msample_var\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgroups\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgroups\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    591\u001b[39m \u001b[43m                       \u001b[49m\u001b[43mcache_values\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcache_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    592\u001b[39m \u001b[43m                       \u001b[49m\u001b[43minference\u001b[49m\u001b[43m=\u001b[49m\u001b[43minference\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Library/Caches/pypoetry/virtualenvs/dml-r0_m-wiA-py3.11/lib/python3.11/site-packages/econml/dml/_rlearner.py:415\u001b[39m, in \u001b[36m_RLearner.fit\u001b[39m\u001b[34m(self, Y, T, X, W, sample_weight, freq_weight, sample_var, groups, cache_values, inference)\u001b[39m\n\u001b[32m    378\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    379\u001b[39m \u001b[33;03mEstimate the counterfactual model from data, i.e. estimates function :math:`\\\\theta(\\\\cdot)`.\u001b[39;00m\n\u001b[32m    380\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m    412\u001b[39m \u001b[33;03mself: _RLearner instance\u001b[39;00m\n\u001b[32m    413\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    414\u001b[39m \u001b[38;5;66;03m# Replacing fit from _OrthoLearner, to enforce Z=None and improve the docstring\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m415\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mY\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mT\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m=\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mW\u001b[49m\u001b[43m=\u001b[49m\u001b[43mW\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    416\u001b[39m \u001b[43m                   \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m=\u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfreq_weight\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfreq_weight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample_var\u001b[49m\u001b[43m=\u001b[49m\u001b[43msample_var\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgroups\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgroups\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    417\u001b[39m \u001b[43m                   \u001b[49m\u001b[43mcache_values\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcache_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    418\u001b[39m \u001b[43m                   \u001b[49m\u001b[43minference\u001b[49m\u001b[43m=\u001b[49m\u001b[43minference\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Library/Caches/pypoetry/virtualenvs/dml-r0_m-wiA-py3.11/lib/python3.11/site-packages/econml/_cate_estimator.py:131\u001b[39m, in \u001b[36mBaseCateEstimator._wrap_fit.<locals>.call\u001b[39m\u001b[34m(self, Y, T, inference, *args, **kwargs)\u001b[39m\n\u001b[32m    129\u001b[39m     inference.prefit(\u001b[38;5;28mself\u001b[39m, Y, T, *args, **kwargs)\n\u001b[32m    130\u001b[39m \u001b[38;5;66;03m# call the wrapped fit method\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m131\u001b[39m \u001b[43mm\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mY\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mT\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    132\u001b[39m \u001b[38;5;28mself\u001b[39m._postfit(Y, T, *args, **kwargs)\n\u001b[32m    133\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m inference \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    134\u001b[39m     \u001b[38;5;66;03m# NOTE: we call inference fit *after* calling the main fit method\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Library/Caches/pypoetry/virtualenvs/dml-r0_m-wiA-py3.11/lib/python3.11/site-packages/econml/_ortho_learner.py:822\u001b[39m, in \u001b[36m_OrthoLearner.fit\u001b[39m\u001b[34m(self, Y, T, X, W, Z, sample_weight, freq_weight, sample_var, groups, cache_values, inference, only_final, check_input)\u001b[39m\n\u001b[32m    820\u001b[39m     nuisances, fitted_models, new_inds, scores = ray.get(\u001b[38;5;28mself\u001b[39m.nuisances_ref[idx])\n\u001b[32m    821\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m822\u001b[39m     nuisances, fitted_models, new_inds, scores = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_fit_nuisances\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    823\u001b[39m \u001b[43m        \u001b[49m\u001b[43mY\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mT\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mW\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mZ\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m=\u001b[49m\u001b[43msample_weight_nuisances\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgroups\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgroups\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    824\u001b[39m all_nuisances.append(nuisances)\n\u001b[32m    825\u001b[39m \u001b[38;5;28mself\u001b[39m._models_nuisance.append(fitted_models)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Library/Caches/pypoetry/virtualenvs/dml-r0_m-wiA-py3.11/lib/python3.11/site-packages/econml/_ortho_learner.py:972\u001b[39m, in \u001b[36m_OrthoLearner._fit_nuisances\u001b[39m\u001b[34m(self, Y, T, X, W, Z, sample_weight, groups)\u001b[39m\n\u001b[32m    969\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    970\u001b[39m         folds = splitter.split(to_split, strata)\n\u001b[32m--> \u001b[39m\u001b[32m972\u001b[39m nuisances, fitted_models, fitted_inds, scores = \u001b[43m_crossfit\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_ortho_learner_model_nuisance\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfolds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    973\u001b[39m \u001b[43m                                                          \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43muse_ray\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mray_remote_func_options\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mY\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mT\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    974\u001b[39m \u001b[43m                                                          \u001b[49m\u001b[43mX\u001b[49m\u001b[43m=\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mW\u001b[49m\u001b[43m=\u001b[49m\u001b[43mW\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mZ\u001b[49m\u001b[43m=\u001b[49m\u001b[43mZ\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m=\u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    975\u001b[39m \u001b[43m                                                          \u001b[49m\u001b[43mgroups\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgroups\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    976\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m nuisances, fitted_models, fitted_inds, scores\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Library/Caches/pypoetry/virtualenvs/dml-r0_m-wiA-py3.11/lib/python3.11/site-packages/econml/_ortho_learner.py:280\u001b[39m, in \u001b[36m_crossfit\u001b[39m\u001b[34m(models, folds, use_ray, ray_remote_fun_option, *args, **kwargs)\u001b[39m\n\u001b[32m    278\u001b[39m     nuisance_temp, model_out, score_temp = ray.get(fold_refs[idx])\n\u001b[32m    279\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m280\u001b[39m     nuisance_temp, model_out, score_temp = \u001b[43m_fit_fold\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_idxs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_idxs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    281\u001b[39m \u001b[43m                                                     \u001b[49m\u001b[43mcalculate_scores\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maccumulated_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    283\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m idx == \u001b[32m0\u001b[39m:\n\u001b[32m    284\u001b[39m     nuisances = \u001b[38;5;28mtuple\u001b[39m([np.full((n,) + nuis.shape[\u001b[32m1\u001b[39m:], np.nan)\n\u001b[32m    285\u001b[39m                       \u001b[38;5;28;01mfor\u001b[39;00m nuis \u001b[38;5;129;01min\u001b[39;00m nuisance_temp])\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Library/Caches/pypoetry/virtualenvs/dml-r0_m-wiA-py3.11/lib/python3.11/site-packages/econml/_ortho_learner.py:99\u001b[39m, in \u001b[36m_fit_fold\u001b[39m\u001b[34m(model, train_idxs, test_idxs, calculate_scores, args, kwargs)\u001b[39m\n\u001b[32m     96\u001b[39m kwargs_train = {key: var[train_idxs] \u001b[38;5;28;01mfor\u001b[39;00m key, var \u001b[38;5;129;01min\u001b[39;00m kwargs.items()}\n\u001b[32m     97\u001b[39m kwargs_test = {key: var[test_idxs] \u001b[38;5;28;01mfor\u001b[39;00m key, var \u001b[38;5;129;01min\u001b[39;00m kwargs.items()}\n\u001b[32m---> \u001b[39m\u001b[32m99\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    100\u001b[39m nuisance_temp = model.predict(*args_test, **kwargs_test)\n\u001b[32m    102\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(nuisance_temp, \u001b[38;5;28mtuple\u001b[39m):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Library/Caches/pypoetry/virtualenvs/dml-r0_m-wiA-py3.11/lib/python3.11/site-packages/econml/dml/_rlearner.py:55\u001b[39m, in \u001b[36m_ModelNuisance.train\u001b[39m\u001b[34m(self, is_selecting, folds, Y, T, X, W, Z, sample_weight, groups)\u001b[39m\n\u001b[32m     52\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m Z \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[33m\"\u001b[39m\u001b[33mCannot accept instrument!\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m     53\u001b[39m \u001b[38;5;28mself\u001b[39m._model_t.train(is_selecting, folds, X, W, T, **\n\u001b[32m     54\u001b[39m                     filter_none_kwargs(sample_weight=sample_weight, groups=groups))\n\u001b[32m---> \u001b[39m\u001b[32m55\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_model_y\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mis_selecting\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfolds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mW\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mY\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\n\u001b[32m     56\u001b[39m \u001b[43m                    \u001b[49m\u001b[43mfilter_none_kwargs\u001b[49m\u001b[43m(\u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m=\u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgroups\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgroups\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     57\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Library/Caches/pypoetry/virtualenvs/dml-r0_m-wiA-py3.11/lib/python3.11/site-packages/econml/dml/dml.py:95\u001b[39m, in \u001b[36m_FirstStageSelector.train\u001b[39m\u001b[34m(self, is_selecting, folds, X, W, Target, sample_weight, groups)\u001b[39m\n\u001b[32m     91\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33mProvided crossfit folds contain training splits that \u001b[39m\u001b[33m\"\u001b[39m +\n\u001b[32m     92\u001b[39m                              \u001b[33m\"\u001b[39m\u001b[33mdon\u001b[39m\u001b[33m'\u001b[39m\u001b[33mt contain all treatments\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     93\u001b[39m     Target = inverse_onehot(Target)\n\u001b[32m---> \u001b[39m\u001b[32m95\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_model\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mis_selecting\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfolds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_combine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mW\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mTarget\u001b[49m\u001b[43m.\u001b[49m\u001b[43mshape\u001b[49m\u001b[43m[\u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mTarget\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     96\u001b[39m \u001b[43m                  \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mfilter_none_kwargs\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgroups\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgroups\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m=\u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     97\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Library/Caches/pypoetry/virtualenvs/dml-r0_m-wiA-py3.11/lib/python3.11/site-packages/econml/sklearn_extensions/model_selection.py:407\u001b[39m, in \u001b[36mFixedModelSelector.train\u001b[39m\u001b[34m(self, is_selecting, folds, X, y, groups, **kwargs)\u001b[39m\n\u001b[32m    404\u001b[39m         \u001b[38;5;28mself\u001b[39m._score = np.mean(scores)\n\u001b[32m    405\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    406\u001b[39m     \u001b[38;5;66;03m# we need to train the model on the data\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m407\u001b[39m     \u001b[43m_fit_with_groups\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgroups\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgroups\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    409\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Library/Caches/pypoetry/virtualenvs/dml-r0_m-wiA-py3.11/lib/python3.11/site-packages/econml/sklearn_extensions/model_selection.py:378\u001b[39m, in \u001b[36m_fit_with_groups\u001b[39m\u001b[34m(model, X, y, sub_model, groups, **kwargs)\u001b[39m\n\u001b[32m    375\u001b[39m             sub_model.cv = old_cv\n\u001b[32m    377\u001b[39m \u001b[38;5;66;03m# drop groups from arg list, which were already used at the outer level and may not be supported by the model\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m378\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmodel\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Library/Caches/pypoetry/virtualenvs/dml-r0_m-wiA-py3.11/lib/python3.11/site-packages/catboost/core.py:5873\u001b[39m, in \u001b[36mCatBoostRegressor.fit\u001b[39m\u001b[34m(self, X, y, cat_features, text_features, embedding_features, graph, sample_weight, baseline, use_best_model, eval_set, verbose, logging_level, plot, plot_file, column_description, verbose_eval, metric_period, silent, early_stopping_rounds, save_snapshot, snapshot_file, snapshot_interval, init_model, callbacks, log_cout, log_cerr)\u001b[39m\n\u001b[32m   5871\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[33m'\u001b[39m\u001b[33mloss_function\u001b[39m\u001b[33m'\u001b[39m \u001b[38;5;129;01min\u001b[39;00m params:\n\u001b[32m   5872\u001b[39m     CatBoostRegressor._check_is_compatible_loss(params[\u001b[33m'\u001b[39m\u001b[33mloss_function\u001b[39m\u001b[33m'\u001b[39m])\n\u001b[32m-> \u001b[39m\u001b[32m5873\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_fit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcat_features\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtext_features\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43membedding_features\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgraph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbaseline\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   5874\u001b[39m \u001b[43m                 \u001b[49m\u001b[43muse_best_model\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43meval_set\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogging_level\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mplot\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mplot_file\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcolumn_description\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   5875\u001b[39m \u001b[43m                 \u001b[49m\u001b[43mverbose_eval\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetric_period\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msilent\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mearly_stopping_rounds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   5876\u001b[39m \u001b[43m                 \u001b[49m\u001b[43msave_snapshot\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msnapshot_file\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msnapshot_interval\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minit_model\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlog_cout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlog_cerr\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Library/Caches/pypoetry/virtualenvs/dml-r0_m-wiA-py3.11/lib/python3.11/site-packages/catboost/core.py:2410\u001b[39m, in \u001b[36mCatBoost._fit\u001b[39m\u001b[34m(self, X, y, cat_features, text_features, embedding_features, pairs, graph, sample_weight, group_id, group_weight, subgroup_id, pairs_weight, baseline, use_best_model, eval_set, verbose, logging_level, plot, plot_file, column_description, verbose_eval, metric_period, silent, early_stopping_rounds, save_snapshot, snapshot_file, snapshot_interval, init_model, callbacks, log_cout, log_cerr)\u001b[39m\n\u001b[32m   2407\u001b[39m allow_clear_pool = train_params[\u001b[33m\"\u001b[39m\u001b[33mallow_clear_pool\u001b[39m\u001b[33m\"\u001b[39m]\n\u001b[32m   2409\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m plot_wrapper(plot, plot_file, \u001b[33m'\u001b[39m\u001b[33mTraining plots\u001b[39m\u001b[33m'\u001b[39m, [_get_train_dir(\u001b[38;5;28mself\u001b[39m.get_params())]):\n\u001b[32m-> \u001b[39m\u001b[32m2410\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_train\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   2411\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtrain_pool\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2412\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtrain_params\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43meval_sets\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2413\u001b[39m \u001b[43m        \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2414\u001b[39m \u001b[43m        \u001b[49m\u001b[43mallow_clear_pool\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2415\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtrain_params\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43minit_model\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[32m   2416\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2418\u001b[39m \u001b[38;5;66;03m# Have property feature_importance possibly set\u001b[39;00m\n\u001b[32m   2419\u001b[39m loss = \u001b[38;5;28mself\u001b[39m._object._get_loss_function_name()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Library/Caches/pypoetry/virtualenvs/dml-r0_m-wiA-py3.11/lib/python3.11/site-packages/catboost/core.py:1790\u001b[39m, in \u001b[36m_CatBoostBase._train\u001b[39m\u001b[34m(self, train_pool, test_pool, params, allow_clear_pool, init_model)\u001b[39m\n\u001b[32m   1789\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_train\u001b[39m(\u001b[38;5;28mself\u001b[39m, train_pool, test_pool, params, allow_clear_pool, init_model):\n\u001b[32m-> \u001b[39m\u001b[32m1790\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_object\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_train\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_pool\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_pool\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mallow_clear_pool\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minit_model\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_object\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43minit_model\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[32m   1791\u001b[39m     \u001b[38;5;28mself\u001b[39m._set_trained_model_attributes()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m_catboost.pyx:5023\u001b[39m, in \u001b[36m_catboost._CatBoost._train\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m_catboost.pyx:5072\u001b[39m, in \u001b[36m_catboost._CatBoost._train\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "seed = 42\n",
    "n_boot = 500\n",
    "unique_groups = np.unique(G)\n",
    "rng = np.random.RandomState(42)\n",
    "\n",
    "# Cluster Bootstrap\n",
    "ate = list()\n",
    "for b in tqdm.tqdm(range(n_boot)):\n",
    "    sampled_groups = rng.choice(unique_groups, size=len(unique_groups), replace=True)\n",
    "    idx = np.concatenate([np.where(G == g)[0] for g in sampled_groups])\n",
    "\n",
    "    dml_b = LinearDML(\n",
    "        model_y = model_y,\n",
    "        model_t = model_t, \n",
    "        discrete_treatment=True,\n",
    "        cv = GroupStratifiedKFold(n_splits=3)\n",
    "    )\n",
    "    dml_b.fit(Y.values.ravel()[idx],\n",
    "              T.values.ravel()[idx],\n",
    "              W=W.values[idx],\n",
    "              groups=G.values[idx])\n",
    "\n",
    "    ate.append(dml_b.ate())\n",
    "    file_name = f\"{b:02d}.joblib\"\n",
    "    file_path = models / file_name\n",
    "    joblib.dump(dml_b, file_path, compress=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49c2d118-ac41-446d-a479-dda84aa4e849",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb6b0a5c-39ab-426c-863e-a4682cff7863",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
